{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport pickle\n#import re\n#import nltk\n#from datetime import datetime\n#from nltk.corpus import stopwords\n#from nltk.corpus import wordnet\n#from nltk.stem import WordNetLemmatizer\n#from nltk import PorterStemmer, LancasterStemmer, SnowballStemmer\n#from nltk.tokenize import word_tokenize\n#from nltk.tokenize import sent_tokenize\n#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n#from sklearn.feature_extraction.text import CountVectorizer\n#from sklearn.preprocessing import OneHotEncoder\n#from sklearn.model_selection import cross_val_score\n#import datetime\n\nfrom sklearn.metrics import precision_recall_curve, average_precision_score\nfrom sklearn.metrics import f1_score, roc_curve, auc, roc_auc_score, recall_score, precision_score, accuracy_score\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn import metrics\n\nfrom keras.models import Model\nimport numpy as np\nfrom keras.layers import Input, Dense, Embedding, Activation, Flatten\nfrom keras.layers import Conv1D, GlobalMaxPooling1D, Dropout, Concatenate, SimpleRNN,Bidirectional\nfrom keras.callbacks import EarlyStopping\n\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.preprocessing.text import Tokenizer\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"## Inputs","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/bt5153traintestbertfullsentence/train_data_bert_fullsent.csv', dtype={'label':str})\ntest = pd.read_csv('../input/bt5153traintestbertfullsentence/test_data_bert_fullsent.csv', dtype={'label':str})","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"with open('../input/5153-bert-feature-extraction-negative/negative_bert_dic_2D.pkl','rb') as f:\n    bert_vec_negative_2d_dict= pickle.load(f)","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"with open('../input/5153-bert-feature-extraction-negative/distil_bert_dic_2D.pkl','rb') as f:\n    distilbert_vec_negative_2d_dict= pickle.load(f)","metadata":{"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df_bert_vec_negative_2d = pd.DataFrame({'review_id' : bert_vec_negative_2d_dict.keys(), \n                                'bert_vec_negative_2d' : bert_vec_negative_2d_dict.values()})\n\ndf_distilbert_vec_negative_2d = pd.DataFrame({'review_id' : distilbert_vec_negative_2d_dict.keys(), \n                                'distilbert_vec_negative_2d' : distilbert_vec_negative_2d_dict.values()})","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"df_distilbert_vec_negative_2d","metadata":{"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      review_id                         distilbert_vec_negative_2d\n0             2  [[[0.21047214, -0.18571095, 0.26193318, -0.090...\n1            12  [[[0.22862941, -0.03539658, -0.038774937, -0.2...\n2            13  [[[0.008773848, 0.073270224, 0.0376536, -0.386...\n3            14  [[[0.2728221, 0.06639026, -0.11520613, -0.2626...\n4            23  [[[0.25766477, -0.03353919, 0.10187317, -0.162...\n...         ...                                                ...\n1518      39704  [[[0.049246475, -0.14651816, -0.14440836, -0.4...\n1519       2002  [[[0.06644378, -0.06282951, -0.023792485, -0.1...\n1520      38681  [[[0.23082301, 0.0028012365, -0.036188904, -0....\n1521      18735  [[[0.26668787, -0.07263901, -0.032762446, -0.2...\n1522      29819  [[[0.19847101, -0.08395584, -0.018514417, -0.3...\n\n[1523 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>distilbert_vec_negative_2d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>[[[0.21047214, -0.18571095, 0.26193318, -0.090...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>[[[0.22862941, -0.03539658, -0.038774937, -0.2...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>13</td>\n      <td>[[[0.008773848, 0.073270224, 0.0376536, -0.386...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>14</td>\n      <td>[[[0.2728221, 0.06639026, -0.11520613, -0.2626...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>23</td>\n      <td>[[[0.25766477, -0.03353919, 0.10187317, -0.162...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1518</th>\n      <td>39704</td>\n      <td>[[[0.049246475, -0.14651816, -0.14440836, -0.4...</td>\n    </tr>\n    <tr>\n      <th>1519</th>\n      <td>2002</td>\n      <td>[[[0.06644378, -0.06282951, -0.023792485, -0.1...</td>\n    </tr>\n    <tr>\n      <th>1520</th>\n      <td>38681</td>\n      <td>[[[0.23082301, 0.0028012365, -0.036188904, -0....</td>\n    </tr>\n    <tr>\n      <th>1521</th>\n      <td>18735</td>\n      <td>[[[0.26668787, -0.07263901, -0.032762446, -0.2...</td>\n    </tr>\n    <tr>\n      <th>1522</th>\n      <td>29819</td>\n      <td>[[[0.19847101, -0.08395584, -0.018514417, -0.3...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1523 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = train.merge(df_bert_vec_negative_2d, on='review_id')\ntrain = train.merge(df_distilbert_vec_negative_2d, on='review_id')\n\ntest = test.merge(df_bert_vec_negative_2d, on='review_id')\ntest = test.merge(df_distilbert_vec_negative_2d, on='review_id')","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"   review_id                                     review_content  review_stars  \\\n0       9161  Delivery took more than a week, short expiry d...             2   \n1       8198  Quality is so-so, loops are too huge resulting...             3   \n2       5314  Received within 3days. Well packed in a carton...             4   \n3      17589  Not sure if these were the authentic as I brou...             3   \n4      31446  its a fashion mask. no filter so no protection...             3   \n\n   delivery  product  service  \\\n0         1        1        0   \n1         0        1        0   \n2         0        1        0   \n3         0        1        0   \n4         0        1        0   \n\n                                            bert_avg  \\\n0  [-0.06329992, -0.32380387, 0.35608995, -0.1268...   \n1  [0.19020107, -0.3453789, 0.3494842, 0.14938574...   \n2  [-0.028732965, -0.14712504, 0.36105582, 0.0254...   \n3  [0.3033499, 0.02644875, 0.16410081, 0.04581299...   \n4  [-0.18616518, -0.38300017, 0.52194715, 0.18413...   \n\n                                            bert_max  \\\n0  [0.93797976, 0.25249124, 1.1054325, 0.49609792...   \n1  [1.1594802, 0.60506886, 1.084206, 0.8051733, 0...   \n2  [1.3182856, 0.7953221, 1.3915914, 0.87499446, ...   \n3  [1.2807441, 0.85781705, 0.80655, 0.49130562, 0...   \n4  [0.65815246, 0.20897251, 1.0151551, 0.48899576...   \n\n                                         bert_layer0  \\\n0  [-0.19600664, -0.4481723, 0.20494524, -0.39789...   \n1  [0.04546422, -0.29597518, -0.35977763, -0.4039...   \n2  [-0.38282838, -0.22101544, 0.6115111, -0.33658...   \n3  [-0.078149214, 0.117149524, 0.04559862, -0.218...   \n4  [-0.29987, -0.26352054, 0.3190687, -0.22115439...   \n\n                                     distil_bert_avg  \\\n0  [-0.046782605, -0.27473888, 0.2780265, 0.03694...   \n1  [0.1399654, -0.11672436, 0.23911656, 0.1187961...   \n2  [0.07374873, -0.01620108, 0.20269494, 0.149083...   \n3  [0.18770164, 0.114881225, 0.08257794, 0.121869...   \n4  [-0.0903255, -0.1808794, 0.33290026, 0.2622123...   \n\n                                     distil_bert_max  \\\n0  [0.4727717, 0.23103717, 0.7197178, 0.6083572, ...   \n1  [0.8445691, 0.4961368, 0.7105234, 0.6109599, 0...   \n2  [0.76418287, 0.48008785, 0.97139245, 0.5615782...   \n3  [0.9882787, 0.5043827, 0.54232115, 0.44097498,...   \n4  [0.66676205, 0.099603325, 0.8990194, 0.5398592...   \n\n                                  distil_bert_layer0 label  \\\n0  [-0.022450736, -0.34166092, 0.13424423, -0.170...   110   \n1  [0.12642525, -0.1857245, 0.08149249, -0.019622...   010   \n2  [0.026645288, -0.27306008, 0.20750262, 0.05986...   010   \n3  [0.23179623, 0.050810635, 0.07551272, -0.15587...   010   \n4  [-0.34698877, -0.3470553, 0.3122651, 0.0037901...   010   \n\n                                bert_vec_negative_2d  \\\n0  [[0.008233139, -0.25179085, 0.32657608, -0.340...   \n1  [[0.2544121, 0.007479055, -0.28748313, -0.0733...   \n2  [[0.54636973, 0.17431441, -0.31171578, -0.0738...   \n3  [[0.21767586, 0.31216693, 0.19653973, -0.22773...   \n4  [[0.44435316, 0.07183391, -0.11268455, -0.1090...   \n\n                          distilbert_vec_negative_2d  \n0  [[[0.056987256, -0.2574688, 0.20414719, -0.574...  \n1  [[[0.28413913, -0.12802139, -0.0026180872, -0....  \n2  [[[0.3668539, 0.0733007, 0.0052855313, -0.3511...  \n3  [[[0.36659744, 0.14379221, 0.07114556, -0.2304...  \n4  [[[0.28633064, -0.097169034, -0.08996225, -0.2...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>review_content</th>\n      <th>review_stars</th>\n      <th>delivery</th>\n      <th>product</th>\n      <th>service</th>\n      <th>bert_avg</th>\n      <th>bert_max</th>\n      <th>bert_layer0</th>\n      <th>distil_bert_avg</th>\n      <th>distil_bert_max</th>\n      <th>distil_bert_layer0</th>\n      <th>label</th>\n      <th>bert_vec_negative_2d</th>\n      <th>distilbert_vec_negative_2d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9161</td>\n      <td>Delivery took more than a week, short expiry d...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.06329992, -0.32380387, 0.35608995, -0.1268...</td>\n      <td>[0.93797976, 0.25249124, 1.1054325, 0.49609792...</td>\n      <td>[-0.19600664, -0.4481723, 0.20494524, -0.39789...</td>\n      <td>[-0.046782605, -0.27473888, 0.2780265, 0.03694...</td>\n      <td>[0.4727717, 0.23103717, 0.7197178, 0.6083572, ...</td>\n      <td>[-0.022450736, -0.34166092, 0.13424423, -0.170...</td>\n      <td>110</td>\n      <td>[[0.008233139, -0.25179085, 0.32657608, -0.340...</td>\n      <td>[[[0.056987256, -0.2574688, 0.20414719, -0.574...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8198</td>\n      <td>Quality is so-so, loops are too huge resulting...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0.19020107, -0.3453789, 0.3494842, 0.14938574...</td>\n      <td>[1.1594802, 0.60506886, 1.084206, 0.8051733, 0...</td>\n      <td>[0.04546422, -0.29597518, -0.35977763, -0.4039...</td>\n      <td>[0.1399654, -0.11672436, 0.23911656, 0.1187961...</td>\n      <td>[0.8445691, 0.4961368, 0.7105234, 0.6109599, 0...</td>\n      <td>[0.12642525, -0.1857245, 0.08149249, -0.019622...</td>\n      <td>010</td>\n      <td>[[0.2544121, 0.007479055, -0.28748313, -0.0733...</td>\n      <td>[[[0.28413913, -0.12802139, -0.0026180872, -0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5314</td>\n      <td>Received within 3days. Well packed in a carton...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.028732965, -0.14712504, 0.36105582, 0.0254...</td>\n      <td>[1.3182856, 0.7953221, 1.3915914, 0.87499446, ...</td>\n      <td>[-0.38282838, -0.22101544, 0.6115111, -0.33658...</td>\n      <td>[0.07374873, -0.01620108, 0.20269494, 0.149083...</td>\n      <td>[0.76418287, 0.48008785, 0.97139245, 0.5615782...</td>\n      <td>[0.026645288, -0.27306008, 0.20750262, 0.05986...</td>\n      <td>010</td>\n      <td>[[0.54636973, 0.17431441, -0.31171578, -0.0738...</td>\n      <td>[[[0.3668539, 0.0733007, 0.0052855313, -0.3511...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17589</td>\n      <td>Not sure if these were the authentic as I brou...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0.3033499, 0.02644875, 0.16410081, 0.04581299...</td>\n      <td>[1.2807441, 0.85781705, 0.80655, 0.49130562, 0...</td>\n      <td>[-0.078149214, 0.117149524, 0.04559862, -0.218...</td>\n      <td>[0.18770164, 0.114881225, 0.08257794, 0.121869...</td>\n      <td>[0.9882787, 0.5043827, 0.54232115, 0.44097498,...</td>\n      <td>[0.23179623, 0.050810635, 0.07551272, -0.15587...</td>\n      <td>010</td>\n      <td>[[0.21767586, 0.31216693, 0.19653973, -0.22773...</td>\n      <td>[[[0.36659744, 0.14379221, 0.07114556, -0.2304...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31446</td>\n      <td>its a fashion mask. no filter so no protection...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.18616518, -0.38300017, 0.52194715, 0.18413...</td>\n      <td>[0.65815246, 0.20897251, 1.0151551, 0.48899576...</td>\n      <td>[-0.29987, -0.26352054, 0.3190687, -0.22115439...</td>\n      <td>[-0.0903255, -0.1808794, 0.33290026, 0.2622123...</td>\n      <td>[0.66676205, 0.099603325, 0.8990194, 0.5398592...</td>\n      <td>[-0.34698877, -0.3470553, 0.3122651, 0.0037901...</td>\n      <td>010</td>\n      <td>[[0.44435316, 0.07183391, -0.11268455, -0.1090...</td>\n      <td>[[[0.28633064, -0.097169034, -0.08996225, -0.2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train.iloc[0, -1][0].shape","metadata":{"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"(106, 768)"},"metadata":{}}]},{"cell_type":"code","source":"sequence_length = 106\nvector_length = 768\ninput_shape = (sequence_length,vector_length)\nmodel_input = Input(shape=input_shape)","metadata":{"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Convolutional Layer \nconv_blocks = []\n#capture two-grams, 3-grams and 4 grams\nfilter_sizes = [2,3,4]\n#for each filter, the number of filters\nnum_filters = 30\n#loop over the different filter sizes\nfor sz in filter_sizes:\n    # sz is the window size\n    conv = Conv1D(filters=num_filters,\n                  kernel_size=sz,\n                  padding=\"valid\",\n                  activation=\"relu\",\n                  strides=1)(model_input)\n    # Pooling Layer\n    conv = GlobalMaxPooling1D()(conv)\n    conv_blocks.append(conv)\n# Fully-connected Layer\nhiddenz = Concatenate()(conv_blocks) if len(conv_blocks) > 1 else conv_blocks[0]","metadata":{"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# It is binary classifcation problem. We can use sigmoid layer.\n# If it is multi-class classifcaiton problem, we can use softmax layer \nmodel_output = Dense(3, activation=\"sigmoid\")(hiddenz)\ncnn_model = Model(model_input, model_output)\ncnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"AUC\"])","metadata":{"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"print(cnn_model.summary())","metadata":{"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Model: \"model\"\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_1 (InputLayer)            [(None, 106, 768)]   0                                            \n__________________________________________________________________________________________________\nconv1d (Conv1D)                 (None, 105, 30)      46110       input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1d_1 (Conv1D)               (None, 104, 30)      69150       input_1[0][0]                    \n__________________________________________________________________________________________________\nconv1d_2 (Conv1D)               (None, 103, 30)      92190       input_1[0][0]                    \n__________________________________________________________________________________________________\nglobal_max_pooling1d (GlobalMax (None, 30)           0           conv1d[0][0]                     \n__________________________________________________________________________________________________\nglobal_max_pooling1d_1 (GlobalM (None, 30)           0           conv1d_1[0][0]                   \n__________________________________________________________________________________________________\nglobal_max_pooling1d_2 (GlobalM (None, 30)           0           conv1d_2[0][0]                   \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 90)           0           global_max_pooling1d[0][0]       \n                                                                 global_max_pooling1d_1[0][0]     \n                                                                 global_max_pooling1d_2[0][0]     \n__________________________________________________________________________________________________\ndense (Dense)                   (None, 3)            273         concatenate[0][0]                \n==================================================================================================\nTotal params: 207,723\nTrainable params: 207,723\nNon-trainable params: 0\n__________________________________________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### CNN Using Bert Vectors","metadata":{}},{"cell_type":"code","source":"train.bert_vec_negative_2d = train.bert_vec_negative_2d.apply(lambda x: np.array(x))\ntest.bert_vec_negative_2d = test.bert_vec_negative_2d.apply(lambda x: np.array(x))","metadata":{"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train.iloc[0, -2].shape","metadata":{"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(106, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to numpy array\ntrain_data = np.array(list(train['bert_vec_negative_2d']), dtype='float32')\ntest_data = np.array(list(test['bert_vec_negative_2d']), dtype='float32')\ntrain_classes = np.array(train[['delivery', 'product','service']], dtype='int')\ntest_classes = np.array(test[['delivery', 'product','service']], dtype='int')","metadata":{"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape, test_data.shape)\nprint(train_classes.shape, test_classes.shape)","metadata":{"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"(1065, 106, 768) (458, 106, 768)\n(1065, 3) (458, 3)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training\ncnn_model.fit(train_data, train_classes,\n          validation_split=0.1,\n          batch_size=32,\n          epochs=20,\n          callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], \n          verbose=2)","metadata":{"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/20\n30/30 - 6s - loss: 0.5561 - auc: 0.8166 - val_loss: 0.4355 - val_auc: 0.8812\nEpoch 2/20\n30/30 - 0s - loss: 0.2579 - auc: 0.9563 - val_loss: 0.3339 - val_auc: 0.9226\nEpoch 3/20\n30/30 - 0s - loss: 0.1762 - auc: 0.9830 - val_loss: 0.3232 - val_auc: 0.9238\nEpoch 4/20\n30/30 - 0s - loss: 0.1285 - auc: 0.9931 - val_loss: 0.3120 - val_auc: 0.9286\nEpoch 5/20\n30/30 - 0s - loss: 0.1006 - auc: 0.9967 - val_loss: 0.3067 - val_auc: 0.9317\nEpoch 6/20\n30/30 - 0s - loss: 0.0766 - auc: 0.9990 - val_loss: 0.2894 - val_auc: 0.9383\nEpoch 7/20\n30/30 - 0s - loss: 0.0576 - auc: 0.9996 - val_loss: 0.3017 - val_auc: 0.9376\nEpoch 8/20\n30/30 - 0s - loss: 0.0422 - auc: 1.0000 - val_loss: 0.3048 - val_auc: 0.9366\nEpoch 9/20\n30/30 - 0s - loss: 0.0334 - auc: 1.0000 - val_loss: 0.3112 - val_auc: 0.9336\n","output_type":"stream"},{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7efd88ad4f50>"},"metadata":{}}]},{"cell_type":"code","source":"prediction_cnn_bert = cnn_model.predict(test_data)","metadata":{"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"test['delivery_cnn_negative_predp'] = prediction_cnn_bert[:, 0]\ntest['product_cnn_negative_predp'] = prediction_cnn_bert[:, 1]\ntest['service_cnn_negative_predp'] = prediction_cnn_bert[:, 2]","metadata":{"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"test['delivery_cnn_negative_pred'] = test['delivery_cnn_negative_predp'].apply(lambda x: round(x))\ntest['product_cnn_negative_pred'] = test['product_cnn_negative_predp'].apply(lambda x: round(x))\ntest['service_cnn_negative_pred'] =test['service_cnn_negative_predp'].apply(lambda x: round(x))","metadata":{"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def add_pred_target_label(df):\n    df['label_pred'] = df['delivery_cnn_negative_pred']*100 + df['product_cnn_negative_pred']*10 + df['service_cnn_negative_pred']\n    df['label_pred'] = '00'+df['label_pred'].astype('str')\n    df['label_pred'] = df['label_pred'].apply(lambda x: x[-3:])\n    return df","metadata":{"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"#add prediction target label\ntest = add_pred_target_label(test)\n#df_test.loc[df_test.review_id==40625, 'label'] = '010'\nprint(test['label_pred'].unique())","metadata":{"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"['010' '001' '110' '100' '101' '011' '000']\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Result of Delivery from CNN with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test.delivery, test.delivery_cnn_negative_predp)))\nprint(classification_report(test.delivery, test.delivery_cnn_negative_pred))\n\nprint('Result of Product from CNN with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['product'], test.product_cnn_negative_predp)))\nprint(classification_report(test['product'], test.product_cnn_negative_pred))\n\nprint('Result of Service from CNN with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['service'], test.service_cnn_negative_predp)))\nprint(classification_report(test['service'], test.service_cnn_negative_pred))","metadata":{"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Result of Delivery from CNN with Bert vectors\nAUC score: 0.936123758553665\n              precision    recall  f1-score   support\n\n           0       0.93      0.94      0.94       351\n           1       0.79      0.79      0.79       107\n\n    accuracy                           0.90       458\n   macro avg       0.86      0.86      0.86       458\nweighted avg       0.90      0.90      0.90       458\n\nResult of Product from CNN with Bert vectors\nAUC score: 0.9346804511278196\n              precision    recall  f1-score   support\n\n           0       0.84      0.81      0.82       154\n           1       0.90      0.92      0.91       304\n\n    accuracy                           0.88       458\n   macro avg       0.87      0.86      0.87       458\nweighted avg       0.88      0.88      0.88       458\n\nResult of Service from CNN with Bert vectors\nAUC score: 0.8488624338624339\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.89       350\n           1       0.69      0.50      0.58       108\n\n    accuracy                           0.83       458\n   macro avg       0.78      0.72      0.74       458\nweighted avg       0.82      0.83      0.82       458\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Combined Result from CNN with Bert vectors')\nprint(classification_report(test['label'], test.label_pred))","metadata":{"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Combined Result from CNN with Bert vectors\n              precision    recall  f1-score   support\n\n         000       0.00      0.00      0.00         0\n         001       0.68      0.40      0.50        67\n         010       0.86      0.92      0.89       262\n         011       0.29      0.18      0.22        22\n         100       0.77      0.73      0.75        70\n         101       0.25      0.35      0.29        17\n         110       0.38      0.33      0.35        18\n         111       0.00      0.00      0.00         2\n\n    accuracy                           0.73       458\n   macro avg       0.40      0.37      0.38       458\nweighted avg       0.75      0.73      0.73       458\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"#### CNN Distil Bert Vectors","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"trusted":true},"execution_count":28,"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"   review_id                                     review_content  review_stars  \\\n0       9161  Delivery took more than a week, short expiry d...             2   \n1       8198  Quality is so-so, loops are too huge resulting...             3   \n2       5314  Received within 3days. Well packed in a carton...             4   \n3      17589  Not sure if these were the authentic as I brou...             3   \n4      31446  its a fashion mask. no filter so no protection...             3   \n\n   delivery  product  service  \\\n0         1        1        0   \n1         0        1        0   \n2         0        1        0   \n3         0        1        0   \n4         0        1        0   \n\n                                            bert_avg  \\\n0  [-0.06329992, -0.32380387, 0.35608995, -0.1268...   \n1  [0.19020107, -0.3453789, 0.3494842, 0.14938574...   \n2  [-0.028732965, -0.14712504, 0.36105582, 0.0254...   \n3  [0.3033499, 0.02644875, 0.16410081, 0.04581299...   \n4  [-0.18616518, -0.38300017, 0.52194715, 0.18413...   \n\n                                            bert_max  \\\n0  [0.93797976, 0.25249124, 1.1054325, 0.49609792...   \n1  [1.1594802, 0.60506886, 1.084206, 0.8051733, 0...   \n2  [1.3182856, 0.7953221, 1.3915914, 0.87499446, ...   \n3  [1.2807441, 0.85781705, 0.80655, 0.49130562, 0...   \n4  [0.65815246, 0.20897251, 1.0151551, 0.48899576...   \n\n                                         bert_layer0  \\\n0  [-0.19600664, -0.4481723, 0.20494524, -0.39789...   \n1  [0.04546422, -0.29597518, -0.35977763, -0.4039...   \n2  [-0.38282838, -0.22101544, 0.6115111, -0.33658...   \n3  [-0.078149214, 0.117149524, 0.04559862, -0.218...   \n4  [-0.29987, -0.26352054, 0.3190687, -0.22115439...   \n\n                                     distil_bert_avg  \\\n0  [-0.046782605, -0.27473888, 0.2780265, 0.03694...   \n1  [0.1399654, -0.11672436, 0.23911656, 0.1187961...   \n2  [0.07374873, -0.01620108, 0.20269494, 0.149083...   \n3  [0.18770164, 0.114881225, 0.08257794, 0.121869...   \n4  [-0.0903255, -0.1808794, 0.33290026, 0.2622123...   \n\n                                     distil_bert_max  \\\n0  [0.4727717, 0.23103717, 0.7197178, 0.6083572, ...   \n1  [0.8445691, 0.4961368, 0.7105234, 0.6109599, 0...   \n2  [0.76418287, 0.48008785, 0.97139245, 0.5615782...   \n3  [0.9882787, 0.5043827, 0.54232115, 0.44097498,...   \n4  [0.66676205, 0.099603325, 0.8990194, 0.5398592...   \n\n                                  distil_bert_layer0 label  \\\n0  [-0.022450736, -0.34166092, 0.13424423, -0.170...   110   \n1  [0.12642525, -0.1857245, 0.08149249, -0.019622...   010   \n2  [0.026645288, -0.27306008, 0.20750262, 0.05986...   010   \n3  [0.23179623, 0.050810635, 0.07551272, -0.15587...   010   \n4  [-0.34698877, -0.3470553, 0.3122651, 0.0037901...   010   \n\n                                bert_vec_negative_2d  \\\n0  [[0.008233139, -0.25179085, 0.32657608, -0.340...   \n1  [[0.2544121, 0.007479055, -0.28748313, -0.0733...   \n2  [[0.54636973, 0.17431441, -0.31171578, -0.0738...   \n3  [[0.21767586, 0.31216693, 0.19653973, -0.22773...   \n4  [[0.44435316, 0.07183391, -0.11268455, -0.1090...   \n\n                          distilbert_vec_negative_2d  \n0  [[[0.056987256, -0.2574688, 0.20414719, -0.574...  \n1  [[[0.28413913, -0.12802139, -0.0026180872, -0....  \n2  [[[0.3668539, 0.0733007, 0.0052855313, -0.3511...  \n3  [[[0.36659744, 0.14379221, 0.07114556, -0.2304...  \n4  [[[0.28633064, -0.097169034, -0.08996225, -0.2...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>review_content</th>\n      <th>review_stars</th>\n      <th>delivery</th>\n      <th>product</th>\n      <th>service</th>\n      <th>bert_avg</th>\n      <th>bert_max</th>\n      <th>bert_layer0</th>\n      <th>distil_bert_avg</th>\n      <th>distil_bert_max</th>\n      <th>distil_bert_layer0</th>\n      <th>label</th>\n      <th>bert_vec_negative_2d</th>\n      <th>distilbert_vec_negative_2d</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>9161</td>\n      <td>Delivery took more than a week, short expiry d...</td>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.06329992, -0.32380387, 0.35608995, -0.1268...</td>\n      <td>[0.93797976, 0.25249124, 1.1054325, 0.49609792...</td>\n      <td>[-0.19600664, -0.4481723, 0.20494524, -0.39789...</td>\n      <td>[-0.046782605, -0.27473888, 0.2780265, 0.03694...</td>\n      <td>[0.4727717, 0.23103717, 0.7197178, 0.6083572, ...</td>\n      <td>[-0.022450736, -0.34166092, 0.13424423, -0.170...</td>\n      <td>110</td>\n      <td>[[0.008233139, -0.25179085, 0.32657608, -0.340...</td>\n      <td>[[[0.056987256, -0.2574688, 0.20414719, -0.574...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8198</td>\n      <td>Quality is so-so, loops are too huge resulting...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0.19020107, -0.3453789, 0.3494842, 0.14938574...</td>\n      <td>[1.1594802, 0.60506886, 1.084206, 0.8051733, 0...</td>\n      <td>[0.04546422, -0.29597518, -0.35977763, -0.4039...</td>\n      <td>[0.1399654, -0.11672436, 0.23911656, 0.1187961...</td>\n      <td>[0.8445691, 0.4961368, 0.7105234, 0.6109599, 0...</td>\n      <td>[0.12642525, -0.1857245, 0.08149249, -0.019622...</td>\n      <td>010</td>\n      <td>[[0.2544121, 0.007479055, -0.28748313, -0.0733...</td>\n      <td>[[[0.28413913, -0.12802139, -0.0026180872, -0....</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5314</td>\n      <td>Received within 3days. Well packed in a carton...</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.028732965, -0.14712504, 0.36105582, 0.0254...</td>\n      <td>[1.3182856, 0.7953221, 1.3915914, 0.87499446, ...</td>\n      <td>[-0.38282838, -0.22101544, 0.6115111, -0.33658...</td>\n      <td>[0.07374873, -0.01620108, 0.20269494, 0.149083...</td>\n      <td>[0.76418287, 0.48008785, 0.97139245, 0.5615782...</td>\n      <td>[0.026645288, -0.27306008, 0.20750262, 0.05986...</td>\n      <td>010</td>\n      <td>[[0.54636973, 0.17431441, -0.31171578, -0.0738...</td>\n      <td>[[[0.3668539, 0.0733007, 0.0052855313, -0.3511...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>17589</td>\n      <td>Not sure if these were the authentic as I brou...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[0.3033499, 0.02644875, 0.16410081, 0.04581299...</td>\n      <td>[1.2807441, 0.85781705, 0.80655, 0.49130562, 0...</td>\n      <td>[-0.078149214, 0.117149524, 0.04559862, -0.218...</td>\n      <td>[0.18770164, 0.114881225, 0.08257794, 0.121869...</td>\n      <td>[0.9882787, 0.5043827, 0.54232115, 0.44097498,...</td>\n      <td>[0.23179623, 0.050810635, 0.07551272, -0.15587...</td>\n      <td>010</td>\n      <td>[[0.21767586, 0.31216693, 0.19653973, -0.22773...</td>\n      <td>[[[0.36659744, 0.14379221, 0.07114556, -0.2304...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>31446</td>\n      <td>its a fashion mask. no filter so no protection...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>[-0.18616518, -0.38300017, 0.52194715, 0.18413...</td>\n      <td>[0.65815246, 0.20897251, 1.0151551, 0.48899576...</td>\n      <td>[-0.29987, -0.26352054, 0.3190687, -0.22115439...</td>\n      <td>[-0.0903255, -0.1808794, 0.33290026, 0.2622123...</td>\n      <td>[0.66676205, 0.099603325, 0.8990194, 0.5398592...</td>\n      <td>[-0.34698877, -0.3470553, 0.3122651, 0.0037901...</td>\n      <td>010</td>\n      <td>[[0.44435316, 0.07183391, -0.11268455, -0.1090...</td>\n      <td>[[[0.28633064, -0.097169034, -0.08996225, -0.2...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# reduce one dimension, (1, 86, 768) -> (86, 768)\ntrain.loc[:, 'distilbert_vec_negative_2d'] = train.loc[:, 'distilbert_vec_negative_2d'].apply(lambda x: x[0])\ntest.loc[:, 'distilbert_vec_negative_2d'] = test.loc[:, 'distilbert_vec_negative_2d'].apply(lambda x: x[0])","metadata":{"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"test.loc[0, 'distilbert_vec_negative_2d'].shape","metadata":{"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"(106, 768)"},"metadata":{}}]},{"cell_type":"code","source":"# Convert to numpy array\ntrain_data_distilbert = np.array(list(train.distilbert_vec_negative_2d), dtype='float32')\ntest_data_distilbert = np.array(list(test.distilbert_vec_negative_2d), dtype='float32')\n\n# Training\ncnn_model.fit(train_data_distilbert, train_classes,\n          validation_split=0.1,\n          batch_size=32,\n          epochs=20,\n          callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], \n          verbose=2)\n\n# Prediction\nprediction_cnn_distilbert = cnn_model.predict(test_data_distilbert)","metadata":{"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Epoch 1/20\n30/30 - 0s - loss: 0.1510 - auc: 0.9894 - val_loss: 0.2770 - val_auc: 0.9418\nEpoch 2/20\n30/30 - 0s - loss: 0.1052 - auc: 0.9970 - val_loss: 0.2778 - val_auc: 0.9411\nEpoch 3/20\n30/30 - 0s - loss: 0.0804 - auc: 0.9988 - val_loss: 0.2694 - val_auc: 0.9480\nEpoch 4/20\n30/30 - 0s - loss: 0.0614 - auc: 0.9995 - val_loss: 0.2766 - val_auc: 0.9449\nEpoch 5/20\n30/30 - 0s - loss: 0.0471 - auc: 0.9999 - val_loss: 0.2658 - val_auc: 0.9490\nEpoch 6/20\n30/30 - 0s - loss: 0.0388 - auc: 1.0000 - val_loss: 0.2870 - val_auc: 0.9418\nEpoch 7/20\n30/30 - 0s - loss: 0.0312 - auc: 1.0000 - val_loss: 0.2748 - val_auc: 0.9463\nEpoch 8/20\n30/30 - 0s - loss: 0.0279 - auc: 1.0000 - val_loss: 0.2863 - val_auc: 0.9439\n","output_type":"stream"}]},{"cell_type":"code","source":"test['delivery_cnn_distilbert_predp'] = prediction_cnn_distilbert[:, 0]\ntest['product_cnn_distilbert_predp'] = prediction_cnn_distilbert[:, 1]\ntest['service_cnn_distilbert_predp'] = prediction_cnn_distilbert[:, 2]\n\ntest['delivery_cnn_distilbert_pred'] = test['delivery_cnn_distilbert_predp'].apply(lambda x: round(x))\ntest['product_cnn_distilbert_pred'] = test['product_cnn_distilbert_predp'].apply(lambda x: round(x))\ntest['service_cnn_distilbert_pred'] =test['service_cnn_distilbert_predp'].apply(lambda x: round(x))","metadata":{"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"def add_pred_target_label(df):\n    df['label_distilbert_pred'] = df['delivery_cnn_distilbert_pred']*100 + df['product_cnn_distilbert_pred']*10 + df['service_cnn_distilbert_pred']\n    df['label_distilbert_pred'] = '00'+df['label_distilbert_pred'].astype('str')\n    df['label_distilbert_pred'] = df['label_distilbert_pred'].apply(lambda x: x[-3:])\n    return df\n\n#add prediction target label\ntest = add_pred_target_label(test)\n#df_test.loc[df_test.review_id==40625, 'label'] = '010'\nprint(test['label_distilbert_pred'].unique())","metadata":{"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"['010' '001' '101' '100' '011' '110' '000']\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Result of Delivery from CNN with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test.delivery, test.delivery_cnn_distilbert_predp)))\nprint(classification_report(test.delivery, test.delivery_cnn_distilbert_pred))\n\nprint('Result of Product from CNN with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['product'], test.product_cnn_distilbert_predp)))\nprint(classification_report(test['product'], test.product_cnn_distilbert_pred))\n\nprint('Result of Service from CNN with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['service'], test.service_cnn_distilbert_predp)))\nprint(classification_report(test['service'], test.service_cnn_distilbert_pred))","metadata":{"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"Result of Delivery from CNN with Distil Bert vectors\nAUC score: 0.9370823015682829\n              precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93       351\n           1       0.81      0.74      0.77       107\n\n    accuracy                           0.90       458\n   macro avg       0.86      0.84      0.85       458\nweighted avg       0.90      0.90      0.90       458\n\nResult of Product from CNN with Distil Bert vectors\nAUC score: 0.9373291182501708\n              precision    recall  f1-score   support\n\n           0       0.85      0.78      0.81       154\n           1       0.89      0.93      0.91       304\n\n    accuracy                           0.88       458\n   macro avg       0.87      0.85      0.86       458\nweighted avg       0.88      0.88      0.88       458\n\nResult of Service from CNN with Distil Bert vectors\nAUC score: 0.8520899470899472\n              precision    recall  f1-score   support\n\n           0       0.86      0.94      0.90       350\n           1       0.73      0.50      0.59       108\n\n    accuracy                           0.84       458\n   macro avg       0.79      0.72      0.75       458\nweighted avg       0.83      0.84      0.83       458\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Combined Result from CNN with Bert vectors')\nprint(classification_report(test['label'], test.label_distilbert_pred))","metadata":{"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"Combined Result from CNN with Bert vectors\n              precision    recall  f1-score   support\n\n         000       0.00      0.00      0.00         0\n         001       0.66      0.43      0.52        67\n         010       0.86      0.93      0.89       262\n         011       0.27      0.18      0.22        22\n         100       0.74      0.70      0.72        70\n         101       0.33      0.29      0.31        17\n         110       0.29      0.28      0.29        18\n         111       0.00      0.00      0.00         2\n\n    accuracy                           0.73       458\n   macro avg       0.39      0.35      0.37       458\nweighted avg       0.74      0.73      0.73       458\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### RNN with Bert Vectors","metadata":{}},{"cell_type":"code","source":"input_shape = (sequence_length, vector_length)\nmodel_input = Input(shape=input_shape)","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"hidden_output = Bidirectional(SimpleRNN(20))(model_input)\nmodel_output = Dense(3, activation=\"sigmoid\")(hidden_output)","metadata":{"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"rnn_model = Model(model_input, model_output)\nrnn_model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"AUC\"])","metadata":{"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"print(rnn_model.summary())","metadata":{"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_2 (InputLayer)         [(None, 106, 768)]        0         \n_________________________________________________________________\nbidirectional (Bidirectional (None, 40)                31560     \n_________________________________________________________________\ndense_1 (Dense)              (None, 3)                 123       \n=================================================================\nTotal params: 31,683\nTrainable params: 31,683\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"# Training\nrnn_model.fit(train_data, train_classes,\n          validation_split=0.1,\n          batch_size=32,\n          epochs=20,\n          callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], \n          verbose=2)","metadata":{"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Epoch 1/20\n30/30 - 9s - loss: 0.5337 - auc: 0.7846 - val_loss: 0.4983 - val_auc: 0.7991\nEpoch 2/20\n30/30 - 7s - loss: 0.4041 - auc: 0.8931 - val_loss: 0.5041 - val_auc: 0.8095\nEpoch 3/20\n30/30 - 7s - loss: 0.3507 - auc: 0.9224 - val_loss: 0.3891 - val_auc: 0.8894\nEpoch 4/20\n30/30 - 7s - loss: 0.3054 - auc: 0.9422 - val_loss: 0.3642 - val_auc: 0.9072\nEpoch 5/20\n30/30 - 6s - loss: 0.2747 - auc: 0.9540 - val_loss: 0.3503 - val_auc: 0.9131\nEpoch 6/20\n30/30 - 7s - loss: 0.2454 - auc: 0.9649 - val_loss: 0.3385 - val_auc: 0.9202\nEpoch 7/20\n30/30 - 7s - loss: 0.2289 - auc: 0.9684 - val_loss: 0.4203 - val_auc: 0.8762\nEpoch 8/20\n30/30 - 7s - loss: 0.2041 - auc: 0.9766 - val_loss: 0.3151 - val_auc: 0.9284\nEpoch 9/20\n30/30 - 7s - loss: 0.1755 - auc: 0.9832 - val_loss: 0.3375 - val_auc: 0.9206\nEpoch 10/20\n30/30 - 6s - loss: 0.1563 - auc: 0.9875 - val_loss: 0.3732 - val_auc: 0.9058\nEpoch 11/20\n30/30 - 7s - loss: 0.1540 - auc: 0.9874 - val_loss: 0.3426 - val_auc: 0.9190\n","output_type":"stream"},{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7efd87c23210>"},"metadata":{}}]},{"cell_type":"code","source":"# Prediction\nprediction_rnn_bert = rnn_model.predict(test_data)\n\ntest['delivery_rnn_bert_predp'] = prediction_rnn_bert[:, 0]\ntest['product_rnn_bert_predp'] = prediction_rnn_bert[:, 1]\ntest['service_rnn_bert_predp'] = prediction_rnn_bert[:, 2]\n\ntest['delivery_rnn_bert_pred'] = test['delivery_rnn_bert_predp'].apply(lambda x: round(x))\ntest['product_rnn_bert_pred'] = test['product_rnn_bert_predp'].apply(lambda x: round(x))\ntest['service_rnn_bert_pred'] =test['service_rnn_bert_predp'].apply(lambda x: round(x))","metadata":{"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"code","source":"def add_pred_target_label(df):\n    df['label_bert_rnn_pred'] = df['delivery_rnn_bert_pred']*100 + df['product_rnn_bert_pred']*10 + df['service_rnn_bert_pred']\n    df['label_bert_rnn_pred'] = '00'+df['label_bert_rnn_pred'].astype('str')\n    df['label_bert_rnn_pred'] = df['label_bert_rnn_pred'].apply(lambda x: x[-3:])\n    return df\n\n#add prediction target label\ntest = add_pred_target_label(test)\n#df_test.loc[df_test.review_id==40625, 'label'] = '010'\nprint(test['label_bert_rnn_pred'].unique())","metadata":{"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"['010' '101' '001' '000' '100' '011' '110']\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Result of Delivery from rnn with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test.delivery, test.delivery_rnn_bert_predp)))\nprint(classification_report(test.delivery, test.delivery_rnn_bert_pred))\n\nprint('Result of Product from rnn with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['product'], test.product_rnn_bert_predp)))\nprint(classification_report(test['product'], test.product_rnn_bert_pred))\n\nprint('Result of Service from rnn with Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['service'], test.service_rnn_bert_predp)))\nprint(classification_report(test['service'], test.service_rnn_bert_pred))","metadata":{"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Result of Delivery from rnn with Bert vectors\nAUC score: 0.8922437894400511\n              precision    recall  f1-score   support\n\n           0       0.89      0.94      0.92       351\n           1       0.76      0.63      0.69       107\n\n    accuracy                           0.87       458\n   macro avg       0.83      0.78      0.80       458\nweighted avg       0.86      0.87      0.86       458\n\nResult of Product from rnn with Bert vectors\nAUC score: 0.9022342788790157\n              precision    recall  f1-score   support\n\n           0       0.77      0.71      0.74       154\n           1       0.86      0.89      0.88       304\n\n    accuracy                           0.83       458\n   macro avg       0.82      0.80      0.81       458\nweighted avg       0.83      0.83      0.83       458\n\nResult of Service from rnn with Bert vectors\nAUC score: 0.8181216931216931\n              precision    recall  f1-score   support\n\n           0       0.85      0.95      0.90       350\n           1       0.75      0.45      0.57       108\n\n    accuracy                           0.84       458\n   macro avg       0.80      0.70      0.73       458\nweighted avg       0.83      0.84      0.82       458\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Combined Result from RNN with Bert vectors')\nprint(classification_report(test['label'], test.label_bert_rnn_pred))","metadata":{"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Combined Result from RNN with Bert vectors\n              precision    recall  f1-score   support\n\n         000       0.00      0.00      0.00         0\n         001       0.56      0.33      0.42        67\n         010       0.81      0.92      0.86       262\n         011       0.18      0.09      0.12        22\n         100       0.65      0.60      0.62        70\n         101       0.33      0.29      0.31        17\n         110       0.25      0.11      0.15        18\n         111       0.00      0.00      0.00         2\n\n    accuracy                           0.69       458\n   macro avg       0.35      0.29      0.31       458\nweighted avg       0.68      0.69      0.67       458\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### RNN Using Distil Bert Vectors","metadata":{}},{"cell_type":"code","source":"# Training\nrnn_model.fit(train_data_distilbert, train_classes,\n          validation_split=0.1,\n          batch_size=32,\n          epochs=20,\n          callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], \n          verbose=2)","metadata":{"trusted":true},"execution_count":45,"outputs":[{"name":"stdout","text":"Epoch 1/20\n30/30 - 7s - loss: 0.2801 - auc: 0.9471 - val_loss: 0.3963 - val_auc: 0.8879\nEpoch 2/20\n30/30 - 6s - loss: 0.2215 - auc: 0.9700 - val_loss: 0.3356 - val_auc: 0.9167\nEpoch 3/20\n30/30 - 7s - loss: 0.1735 - auc: 0.9827 - val_loss: 0.3473 - val_auc: 0.9158\nEpoch 4/20\n30/30 - 6s - loss: 0.1524 - auc: 0.9868 - val_loss: 0.3486 - val_auc: 0.9161\nEpoch 5/20\n30/30 - 7s - loss: 0.1297 - auc: 0.9914 - val_loss: 0.3596 - val_auc: 0.9146\n","output_type":"stream"},{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7efd86e776d0>"},"metadata":{}}]},{"cell_type":"code","source":"# Prediction\nprediction_rnn_distilbert = rnn_model.predict(test_data_distilbert)\n\ntest['delivery_rnn_distilbert_predp'] = prediction_rnn_distilbert[:, 0]\ntest['product_rnn_distilbert_predp'] = prediction_rnn_distilbert[:, 1]\ntest['service_rnn_distilbert_predp'] = prediction_rnn_distilbert[:, 2]\n\ntest['delivery_rnn_distilbert_pred'] = test['delivery_rnn_distilbert_predp'].apply(lambda x: round(x))\ntest['product_rnn_distilbert_pred'] = test['product_rnn_distilbert_predp'].apply(lambda x: round(x))\ntest['service_rnn_distilbert_pred'] =test['service_rnn_distilbert_predp'].apply(lambda x: round(x))","metadata":{"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def add_pred_target_label(df):\n    df['label_distilbert_rnn_pred'] = df['delivery_rnn_distilbert_pred']*100 + df['product_rnn_distilbert_pred']*10 + df['service_rnn_distilbert_pred']\n    df['label_distilbert_rnn_pred'] = '00'+df['label_distilbert_rnn_pred'].astype('str')\n    df['label_distilbert_rnn_pred'] = df['label_distilbert_rnn_pred'].apply(lambda x: x[-3:])\n    return df\n\n#add prediction target label\ntest = add_pred_target_label(test)\n#df_test.loc[df_test.review_id==40625, 'label'] = '010'\nprint(test['label_distilbert_rnn_pred'].unique())","metadata":{"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"['010' '110' '101' '001' '100' '011' '000' '111']\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Result of Delivery from rnn with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test.delivery, test.delivery_rnn_distilbert_predp)))\nprint(classification_report(test.delivery, test.delivery_rnn_distilbert_pred))\n\nprint('Result of Product from rnn with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['product'], test.product_rnn_distilbert_predp)))\nprint(classification_report(test['product'], test.product_rnn_distilbert_pred))\n\nprint('Result of Service from rnn with Distil Bert vectors')\nprint('AUC score: {}'.format(roc_auc_score(test['service'], test.service_rnn_distilbert_predp)))\nprint(classification_report(test['service'], test.service_rnn_distilbert_pred))","metadata":{"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"Result of Delivery from rnn with Distil Bert vectors\nAUC score: 0.897196261682243\n              precision    recall  f1-score   support\n\n           0       0.91      0.91      0.91       351\n           1       0.70      0.69      0.70       107\n\n    accuracy                           0.86       458\n   macro avg       0.81      0.80      0.80       458\nweighted avg       0.86      0.86      0.86       458\n\nResult of Product from rnn with Distil Bert vectors\nAUC score: 0.9117182159945317\n              precision    recall  f1-score   support\n\n           0       0.80      0.80      0.80       154\n           1       0.90      0.90      0.90       304\n\n    accuracy                           0.86       458\n   macro avg       0.85      0.85      0.85       458\nweighted avg       0.86      0.86      0.86       458\n\nResult of Service from rnn with Distil Bert vectors\nAUC score: 0.8161111111111111\n              precision    recall  f1-score   support\n\n           0       0.88      0.88      0.88       350\n           1       0.61      0.61      0.61       108\n\n    accuracy                           0.81       458\n   macro avg       0.74      0.74      0.74       458\nweighted avg       0.82      0.81      0.81       458\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Combined Result from RNN with Distil Bert vectors')\nprint(classification_report(test['label'], test.label_distilbert_rnn_pred))","metadata":{"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Combined Result from RNN with Distil Bert vectors\n              precision    recall  f1-score   support\n\n         000       0.00      0.00      0.00         0\n         001       0.53      0.46      0.50        67\n         010       0.84      0.86      0.85       262\n         011       0.19      0.18      0.19        22\n         100       0.71      0.63      0.67        70\n         101       0.10      0.18      0.13        17\n         110       0.23      0.17      0.19        18\n         111       0.00      0.00      0.00         2\n\n    accuracy                           0.68       458\n   macro avg       0.33      0.31      0.32       458\nweighted avg       0.69      0.68      0.68       458\n\n","output_type":"stream"}]},{"cell_type":"code","source":"test.to_csv('test_cnn_rnn_negative_pred.csv', index=False)","metadata":{"trusted":true},"execution_count":50,"outputs":[]}]}